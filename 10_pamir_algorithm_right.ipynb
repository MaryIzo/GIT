{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Есть некоторое количество точек на плоскости, для которых известны взаимные расстояния, равные $\\sqrt{E_i*E_j}r_{ij}$, $r_{ij}$ - евклидовое расстояние.  \n",
    "2. Находим точки с минимальным   $\\chi_{ij}$.  \n",
    "3. Точки объединяются в одну, для них пересчитывается расстояние (энергетически взвешенно  $X_{new} = \\frac{E_iX_i + E_jX_j}{E_i+E_j}$) и энергия.  \n",
    "4. Переходим к следующей точке, пока расстояния между всеми точками меньше $\\chi_{ij}$ или точки не закончатся.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.7.9\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "import seaborn as sns\n",
    "import math\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "import datetime\n",
    "le = LabelEncoder()\n",
    "\n",
    "from platform import python_version\n",
    "\n",
    "print(python_version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция подсчета значений коэффициентов\n",
    "\n",
    "def CoefPFI_analysis(df, num, cluster_column, hlabel_column):\n",
    "    \"\"\"\n",
    "    Возвращает значения коэффициентов качества кластеризации в удобном для анализа формате.\n",
    "    \n",
    "    Входные значения:\n",
    "    df - датафрейм. \n",
    "    num - номер семейства.\n",
    "    cluster_column - название колонки с метками кластеров.\n",
    "    hlabel_column - название колонки с метками высот.\n",
    "    \n",
    "    Возвращаемые значение:\n",
    "    Печатает\n",
    "    purity, splitting, integrity, efficiency, mean, compose\n",
    "    \n",
    "    (чистота, фрагментарность, целостность, эффективность, среднее, произведение средних).\n",
    "    \"\"\"\n",
    "    \n",
    "    P = 0\n",
    "    E = 0\n",
    "    DomH = [] #доминирующие высоты в кластерах\n",
    "    N_c = len(df)\n",
    "    \n",
    "    if N_c==0:\n",
    "        print('Empty Family')\n",
    "        return\n",
    "    \n",
    "    labels = df[cluster_column]\n",
    "    \n",
    "    n_clusters_ = len(set(labels))\n",
    "    \n",
    "    for i in range(n_clusters_):\n",
    "        \n",
    "        value = df[df[cluster_column]==i][hlabel_column].value_counts()\n",
    "\n",
    "        n_d = value[:1].values\n",
    "        n_c = len(df[df[cluster_column]==i][hlabel_column])\n",
    "        \n",
    "        \n",
    "        P_i = n_d[0]/n_c\n",
    "        P = P + P_i\n",
    "        \n",
    "        x = value[:1].index[0]\n",
    "        n_t = len(df[df[hlabel_column]==x])\n",
    "        \n",
    "        E_i = n_d[0]/n_t\n",
    "        E = E + E_i\n",
    "        DomH.append(x)\n",
    "    \n",
    "    purity = P/n_clusters_ #1\n",
    "    \n",
    "    splitting = len(set(DomH))/n_clusters_ #2\n",
    "    \n",
    "    integrity = len(set(DomH))/len(set(df[hlabel_column])) #3\n",
    " \n",
    "    efficiency =  E/n_clusters_ #4\n",
    "    \n",
    "    print(f'P = {round(purity,3)}, S = {round(splitting,3)}, I = {round(integrity, 3)}, E = {round(efficiency, 3)}')\n",
    "   \n",
    "    \n",
    "    result = [ num, round(purity, 3), round(splitting,3), round(integrity, 3), round(efficiency,3)] \n",
    "    mean = np.mean(result[1:])\n",
    "    var = np.var(result[1:])\n",
    "    compose = (purity+efficiency)*(integrity+splitting)/4\n",
    "    \n",
    "    result = result + [mean]\n",
    "    result = result +[var]\n",
    "    \n",
    "    \n",
    "    print(f'Mean: {round(mean, 3)}, compose: {round( compose , 3)}')\n",
    "    \n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Matrix_of_Distance(X, Y, E, label=2):\n",
    "    \"\"\"\n",
    "    Возвращает матрицу рассстояний, посчитанную с использованием трёх разных метрик.\n",
    "    label = 1 евклидово расстояние r_ij.\n",
    "    label = 2 домножается на корень из энергий sqrt(e_i*e_j)*r_ij.\n",
    "    label = 3 домножается на дробь (e_i*e_j)/(e_i+e_j)*r_ij.\n",
    "    \n",
    "    Входные значения:\n",
    "    X - координата x, \n",
    "    Y - координата y,\n",
    "    E - энергия, \n",
    "    label - маркер метрики расстояния.\n",
    "    \n",
    "    Возвращаемые значения:\n",
    "    датафрейм матрицы взаимных расстояний.\n",
    "    \"\"\"\n",
    "    # out = попарное евклидовое расстояние\n",
    "    Z = np.array([[complex(X[i], Y[i]) for i in range(len(X))]])\n",
    "    out = abs(Z.T-Z)\n",
    "    \n",
    "    if label==1:\n",
    "        # евклидовое расстояние\n",
    "        oute = 1\n",
    "    elif label==2:\n",
    "        # sqrt(e_i*e_j)\n",
    "        oute = np.sqrt(np.outer(E, E))\n",
    "    elif label==3:\n",
    "        # e_i*e_j/(e_i+e_j)\n",
    "        outmult = np.outer(E, E)\n",
    "        outadd = np.add.outer(list(E), list(E))\n",
    "        oute = outmult/outadd\n",
    "        \n",
    "    # Для треугольной формы    \n",
    "    #oute = np.triu(oute)\n",
    "    return pd.DataFrame(oute*out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Считываем данные модели\n",
    "AllMc0 = pd.read_csv('datachanged/AllMc0C').drop(['Unnamed: 0'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "OneFamily = pd.DataFrame(AllMc0.loc[lambda AllMc0: AllMc0[' num_of_family'] == 1229, :]).copy()\n",
    "OneFamily['Hlabel'] = le.fit_transform(OneFamily['H(J)'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clusters_change(clusters, val_to_change, val):\n",
    "    \"\"\"\n",
    "    Заменяет значение в словаре, который содержит номера кластеров частиц семейства\n",
    "    \n",
    "    Входные значения:\n",
    "    clusters - словарь кластеров \n",
    "    val_to_change - заменяемое значение (не ключ) \n",
    "    val - то значение, на которое нужно заменить\n",
    "    \n",
    "    Выходные значения:\n",
    "    clusters - словарь кластеров\n",
    "    \"\"\"\n",
    "    for key in clusters.keys():\n",
    "        if clusters[key]==val_to_change:\n",
    "            clusters[key] = val\n",
    "    return clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_update(dfv, min_j):\n",
    "    \"\"\"\n",
    "    Обновляет датафрейм, удаляя из него частицу.\n",
    "    \n",
    "    Входные значения:\n",
    "    dfv - значения датафрейма (из метода values).\n",
    "    min_j - номер удаляемой частицы.\n",
    "    \n",
    "    Выходные значения:\n",
    "    dftmp - новый датафрейм.\n",
    "    \"\"\"\n",
    "    \n",
    "    dftmp = pd.DataFrame(dfv)\n",
    "    dftmp = dftmp[dftmp[5]!=min_j].copy().reset_index(drop=True)\n",
    "    check = len(dftmp)\n",
    "    dftmp[5] = [i for i in range(check)]  \n",
    "    return dftmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PamirAlgorithm(OneFamily, \n",
    "                   eps = 48, \n",
    "                   num_name = ' num_of_family',\n",
    "                   j_name = ' j',\n",
    "                   x_name = 'X(J)',\n",
    "                   y_name = 'Y(J)',\n",
    "                   e_name = 'E(J)',\n",
    "                   alg_ind = 'j_new'):\n",
    "    \n",
    "    \"\"\"\n",
    "    Алгоритм Памира для метрики корень из произведения энергий на евклидовое расстояние sqrt(e_i*e_j)*r_ij.\n",
    "    1. Есть некоторое количество точек на плоскости, для которых известны взаимные расстояния.  \n",
    "    2. Находим точки с минимальным взаимным расстоянием.  \n",
    "    3. Точки объединяются в одну энергетически взвешенно  X_new = (e_i*x_i + e_j*x_j)/(e_i+e_j) и энергия e_new = (e_i+e_j).  \n",
    "    4. Переходим к следующей точке, пока расстояния между точками меньше 48 или точки не закончатся. \n",
    "    Значение 48 получено в процессе работы А.С.Борисова, можно изменить для экспериментов.\n",
    "    \n",
    "    Входные значения:\n",
    "    OneFamily - датафрейм кластеризуемого семейства, \n",
    "    eps - параметр остановки, \n",
    "    num_name - имя колонки с номерами семейств,\n",
    "    j_name - имя колонуи с номерами частиц,\n",
    "    x_name - имя колонки с координатой x,\n",
    "    y_name - имя колонки с координатой y,\n",
    "    e_name - имя колонк с энергией,\n",
    "    alg_ind - имя колонки для перенумерации частиц (могут быть пропуски в значениях).\n",
    "    \n",
    "    Возвращаемое значение:\n",
    "    labels - колонка кастеров, порядок соответствует порядку частиц в колонке с номерами частиц j_name.\n",
    "    \"\"\"\n",
    "    \n",
    "    # создадим словарь кластеров, так как нумерация частиц может быть некорректной\n",
    "    points = OneFamily[j_name].unique()\n",
    "    clusters = {}\n",
    "    for k in points:\n",
    "        clusters[k]=-1\n",
    "    k = 0\n",
    "\n",
    "    OneFamily[alg_ind] = [i for i in range(len(OneFamily))] # добавляем вспомогательный индекс для выбрасывания частиц\n",
    "    dfv = OneFamily[[num_name, j_name, x_name, y_name, e_name, alg_ind]].values\n",
    "    dftmp = pd.DataFrame(dfv)\n",
    "    check = len(dftmp)\n",
    "    \n",
    "    if (check==0):\n",
    "        print('Empty Family')\n",
    "        return\n",
    "    \n",
    "    minv = np.inf\n",
    "    #print(check)\n",
    "\n",
    "    while (check!=1) and ((minv < eps) or (minv==np.inf)):\n",
    "\n",
    "        X = dftmp[2].values\n",
    "        Y = dftmp[3].values\n",
    "        E = dftmp[4].values\n",
    "\n",
    "        distm = Matrix_of_Distance(X, Y, E)\n",
    "        l = distm.shape[0]\n",
    "        distm = distm.values\n",
    "\n",
    "        min_i = 0\n",
    "        min_j = 0\n",
    "        minv = np.inf\n",
    "        for j in range(l):\n",
    "            for i in range(j+1, l):\n",
    "                if distm[j][i]< minv:\n",
    "                    min_i = i\n",
    "                    min_j = j\n",
    "                    minv = distm[j][i]\n",
    "\n",
    "        #print(minv, min_i, min_j)\n",
    "\n",
    "\n",
    "        if minv < eps:\n",
    "            # если меньше, объединяем точки\n",
    "            # первая точка\n",
    "            ind_i = dfv[min_i][1]\n",
    "            xi = dfv[min_i][2]\n",
    "            yi = dfv[min_i][3]\n",
    "            ei = dfv[min_i][4]\n",
    "\n",
    "            # вторая точка\n",
    "            ind_j = dfv[min_j][1]\n",
    "            xj = dfv[min_j][2]\n",
    "            yj = dfv[min_j][3]\n",
    "            ej = dfv[min_j][4]\n",
    "            \n",
    "            #print(ind_i, ind_j)\n",
    "            \n",
    "            if (clusters[ind_j]!=-1) and (clusters[ind_i]==-1):\n",
    "                #print('old', ind_j)\n",
    "                #print('max_val=', max(clusters.values()))\n",
    "                clusters[ind_i] = clusters[ind_j]\n",
    "                #print(clusters.values())\n",
    "            elif (clusters[ind_i]!=-1) and (clusters[ind_j]==-1):\n",
    "                #print('old', ind_i)\n",
    "                #print('max_val=', max(clusters.values()))\n",
    "                clusters[ind_j] = clusters[ind_i]\n",
    "                #print(clusters.values())\n",
    "            elif (clusters[ind_j]==-1) or (clusters[ind_i]==-1):\n",
    "                clusters[ind_i] = k\n",
    "                clusters[ind_j] = k\n",
    "                k= k + 1\n",
    "                #print(clusters.values())\n",
    "            else:\n",
    "                #print('two old')\n",
    "\n",
    "                if (clusters[ind_i]!=clusters[ind_j]):\n",
    "\n",
    "                    val_to_change= clusters[ind_i]\n",
    "                    #print('val_to_change=', clusters[ind_i])\n",
    "\n",
    "                    max_val = max(clusters.values())\n",
    "                    #print('max_val=', max_val)\n",
    "\n",
    "                    #print('ind_i ', clusters[ind_i], 'ind_j ', clusters[ind_j])\n",
    "\n",
    "                    # убираем совпавший кластер\n",
    "                    clusters = clusters_change(clusters, val_to_change, clusters[ind_j])\n",
    "\n",
    "                    # заменяем максимальный номер кластера на тот, что убираем\n",
    "                    clusters = clusters_change(clusters, max_val, val_to_change)\n",
    "                    k = k - 1\n",
    "\n",
    "                # после обновления значений создаём новый датафрейм\n",
    "                dftmp = pd.DataFrame(dfv)\n",
    "                dftmp = dftmp[dftmp[5]!=min_j].copy().reset_index(drop=True)\n",
    "                check = len(dftmp)\n",
    "                dftmp[5] = [i for i in range(check)]\n",
    "                dfv = dftmp.values\n",
    "                # проверка длины\n",
    "                check = len(dftmp)\n",
    "                # пересчитываем индексы\n",
    "\n",
    "                #print(clusters.values())\n",
    "                continue\n",
    "\n",
    "            dfv[min_i][1] = ind_i # j\n",
    "            dfv[min_i][2] = (ei*xi+ej*xj)/(ei+ej) # x\n",
    "            dfv[min_i][3] = (ei*yi+ej*yj)/(ei+ej)  # y\n",
    "            dfv[min_i][4] = (ei+ej) # e\n",
    "            dfv[min_i][5] = -1  # j_new\n",
    "            #print(ind_i, ind_j)\n",
    "            #print(min_i, min_j)\n",
    "\n",
    "            # после обновления значений создаём новый датафрейм\n",
    "            dftmp = pd.DataFrame(dfv)\n",
    "            dftmp = dftmp[dftmp[5]!=min_j].copy().reset_index(drop=True)\n",
    "            check = len(dftmp)\n",
    "            dftmp[5] = [i for i in range(check)]\n",
    "            dfv = dftmp.values\n",
    "            # проверка длины\n",
    "            check = len(dftmp) \n",
    "            #print('check =', check)\n",
    "        else:\n",
    "            #print('minv = ', minv)\n",
    "            #print('k = ', k)\n",
    "            for key in clusters.keys():\n",
    "                if clusters[key]==-1:\n",
    "                    clusters[key] = k\n",
    "                    k = k + 1\n",
    "    \n",
    "                    \n",
    "    labels = clusters.values()\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty Family\n",
      "Empty Family\n"
     ]
    }
   ],
   "source": [
    "OneFamily['clust_pam']= PamirAlgorithm(OneFamily)\n",
    "CoefPFI_analysis(OneFamily, ' num_of_fam', 'Hlabel', 'clust_pam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 999,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P = 0.417, S = 1.0, I = 0.333, E = 1.0\n",
      "Mean: 0.688, compose: 0.472\n"
     ]
    }
   ],
   "source": [
    "chiri = np.percentile(OneFamily['ER'],50)\n",
    "OneFamily['clust_pam']= PamirAlgorithm(OneFamily, chiri)\n",
    "CoefPFI_analysis(OneFamily, ' num_of_fam', 'Hlabel', 'clust_pam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1002,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = Matrix_of_Distance(OneFamily['X(J)'].values, OneFamily['Y(J)'].values, OneFamily['E(J)'].values, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1003,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 0, 2, 7, 0, 2, 8, 4, 3, 6, 1], dtype=int64)"
      ]
     },
     "execution_count": 1003,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#linkage: average, complete, single.\n",
    "thr = np.percentile(OneFamily, 50)\n",
    "clustering = AgglomerativeClustering(n_clusters=None, affinity = 'precomputed', distance_threshold = thr, linkage = 'average').fit(X)\n",
    "clustering.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1004,
   "metadata": {},
   "outputs": [],
   "source": [
    "OneFamily['clust_agl']= clustering.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1005,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P = 0.361, S = 1.0, I = 0.222, E = 1.0\n",
      "Mean: 0.646, compose: 0.416\n"
     ]
    }
   ],
   "source": [
    "CoefPFI_analysis(OneFamily, ' num_of_fam', 'Hlabel', 'clust_agl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1025,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clustering(data, name, exp = False):\n",
    "    \"\"\"\n",
    "    Функция для проверки. \n",
    "    Кластеризует все семейства алгоритмом Памир.\n",
    "    \"\"\"\n",
    "    nums =list(set(data[name].values))\n",
    "    clustered_df = []\n",
    "    \n",
    "    print('start: ', datetime.datetime.now())\n",
    "    \n",
    "    for i in nums:\n",
    "        if i%100 == 0:\n",
    "            print(i, datetime.datetime.now())\n",
    "        \n",
    "        df = data[data[name]==i].copy()\n",
    "        \n",
    "        # eps = 48\n",
    "        df['cluster_pam'] = PamirAlgorithm(df)\n",
    "        \n",
    "        clustered_df.append(df)\n",
    "    \n",
    "    clustered_df = pd.concat(clustered_df)\n",
    "\n",
    "    return clustered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1026,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Старый модельный банк.\n",
    "olddata = pd.read_csv('datachanged/AllMc0COld', sep = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1027,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Экспериментальные данные.\n",
    "AllExp = pd.read_csv('datachanged/AllExpC')\n",
    "AllExp = AllExp.drop(['Unnamed: 0'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1028,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start:  2022-03-16 00:22:50.591990\n",
      "10 2022-03-16 00:22:50.915161\n",
      "20 2022-03-16 00:22:51.255247\n",
      "30 2022-03-16 00:22:51.542447\n",
      "40 2022-03-16 00:22:51.896500\n",
      "50 2022-03-16 00:22:52.234598\n",
      "60 2022-03-16 00:22:52.643502\n",
      "80 2022-03-16 00:22:53.969957\n",
      "90 2022-03-16 00:22:54.421748\n",
      "100 2022-03-16 00:22:54.732924\n",
      "110 2022-03-16 00:22:55.244546\n",
      "120 2022-03-16 00:22:55.766153\n",
      "130 2022-03-16 00:22:56.696665\n",
      "140 2022-03-16 00:22:58.059021\n",
      "150 2022-03-16 00:22:58.545718\n",
      "160 2022-03-16 00:22:59.198013\n",
      "170 2022-03-16 00:22:59.597949\n",
      "180 2022-03-16 00:23:00.056716\n",
      "190 2022-03-16 00:23:00.983202\n",
      "200 2022-03-16 00:23:01.625520\n",
      "210 2022-03-16 00:23:02.000517\n",
      "220 2022-03-16 00:23:02.298706\n",
      "230 2022-03-16 00:23:02.554003\n",
      "240 2022-03-16 00:23:02.795358\n",
      "250 2022-03-16 00:23:03.063665\n",
      "260 2022-03-16 00:23:03.293026\n",
      "270 2022-03-16 00:23:03.606188\n",
      "280 2022-03-16 00:23:03.979052\n",
      "290 2022-03-16 00:23:04.505648\n",
      "300 2022-03-16 00:23:04.987324\n",
      "310 2022-03-16 00:23:05.218703\n",
      "320 2022-03-16 00:23:05.509925\n",
      "330 2022-03-16 00:23:05.751279\n",
      "340 2022-03-16 00:23:06.090374\n",
      "350 2022-03-16 00:23:06.446423\n",
      "360 2022-03-16 00:23:06.868295\n",
      "370 2022-03-16 00:23:07.284612\n",
      "380 2022-03-16 00:23:07.623703\n",
      "390 2022-03-16 00:23:08.037569\n",
      "400 2022-03-16 00:23:08.277200\n",
      "410 2022-03-16 00:23:08.884573\n",
      "420 2022-03-16 00:23:09.219704\n",
      "430 2022-03-16 00:23:09.519756\n",
      "440 2022-03-16 00:23:09.870816\n",
      "450 2022-03-16 00:23:10.106187\n",
      "460 2022-03-16 00:23:10.730524\n",
      "470 2022-03-16 00:23:11.283039\n",
      "480 2022-03-16 00:23:12.026089\n",
      "490 2022-03-16 00:23:12.553641\n",
      "500 2022-03-16 00:23:12.985487\n",
      "510 2022-03-16 00:23:13.697584\n",
      "520 2022-03-16 00:23:14.072581\n",
      "530 2022-03-16 00:23:14.359839\n",
      "540 2022-03-16 00:23:14.729824\n",
      "550 2022-03-16 00:23:15.084872\n",
      "560 2022-03-16 00:23:15.456878\n",
      "570 2022-03-16 00:23:15.788699\n",
      "580 2022-03-16 00:23:16.065930\n",
      "590 2022-03-16 00:23:16.355494\n",
      "600 2022-03-16 00:23:16.605166\n",
      "610 2022-03-16 00:23:17.184585\n",
      "620 2022-03-16 00:23:17.517692\n",
      "630 2022-03-16 00:23:17.799970\n",
      "640 2022-03-16 00:23:18.306582\n",
      "650 2022-03-16 00:23:18.871073\n",
      "660 2022-03-16 00:23:19.138506\n",
      "670 2022-03-16 00:23:19.389190\n",
      "680 2022-03-16 00:23:19.653486\n",
      "690 2022-03-16 00:23:19.958670\n",
      "700 2022-03-16 00:23:20.289749\n",
      "710 2022-03-16 00:23:20.601944\n",
      "720 2022-03-16 00:23:21.027799\n",
      "730 2022-03-16 00:23:21.472620\n",
      "740 2022-03-16 00:23:21.774855\n",
      "750 2022-03-16 00:23:22.467003\n",
      "760 2022-03-16 00:23:23.385545\n",
      "770 2022-03-16 00:23:24.366922\n",
      "780 2022-03-16 00:23:24.615259\n",
      "790 2022-03-16 00:23:24.798911\n",
      "800 2022-03-16 00:23:25.628702\n",
      "810 2022-03-16 00:23:26.309876\n",
      "820 2022-03-16 00:23:26.717778\n",
      "830 2022-03-16 00:23:27.597426\n",
      "840 2022-03-16 00:23:27.961483\n",
      "850 2022-03-16 00:23:28.349415\n",
      "860 2022-03-16 00:23:29.643954\n",
      "870 2022-03-16 00:23:30.017955\n",
      "880 2022-03-16 00:23:30.400962\n",
      "890 2022-03-16 00:23:30.865686\n",
      "900 2022-03-16 00:23:31.084104\n",
      "910 2022-03-16 00:23:31.426189\n",
      "920 2022-03-16 00:23:32.287883\n",
      "930 2022-03-16 00:23:32.924227\n",
      "940 2022-03-16 00:23:33.391975\n",
      "950 2022-03-16 00:23:33.864713\n",
      "960 2022-03-16 00:23:34.349414\n",
      "970 2022-03-16 00:23:34.771173\n",
      "980 2022-03-16 00:23:35.166149\n",
      "990 2022-03-16 00:23:35.432404\n",
      "1000 2022-03-16 00:23:35.871234\n",
      "1010 2022-03-16 00:23:36.226283\n",
      "1020 2022-03-16 00:23:36.667103\n",
      "1030 2022-03-16 00:23:37.344292\n",
      "1040 2022-03-16 00:23:37.784156\n",
      "1050 2022-03-16 00:23:38.282633\n",
      "1060 2022-03-16 00:23:39.023656\n",
      "1070 2022-03-16 00:23:40.119727\n",
      "1080 2022-03-16 00:23:40.537610\n",
      "1090 2022-03-16 00:23:41.171919\n",
      "1100 2022-03-16 00:23:41.796245\n",
      "1110 2022-03-16 00:23:42.461462\n",
      "1120 2022-03-16 00:23:42.827486\n",
      "1130 2022-03-16 00:23:43.285260\n",
      "1140 2022-03-16 00:23:44.211783\n",
      "1150 2022-03-16 00:23:44.656597\n",
      "1170 2022-03-16 00:23:45.222081\n",
      "1180 2022-03-16 00:23:45.701806\n",
      "1190 2022-03-16 00:23:46.582483\n",
      "1200 2022-03-16 00:23:46.894651\n",
      "1210 2022-03-16 00:23:47.328489\n",
      "1220 2022-03-16 00:23:47.726424\n",
      "1230 2022-03-16 00:23:48.027474\n",
      "1260 2022-03-16 00:23:48.980960\n",
      "1270 2022-03-16 00:23:49.362899\n",
      "1280 2022-03-16 00:23:50.097934\n",
      "1290 2022-03-16 00:23:50.401124\n"
     ]
    }
   ],
   "source": [
    "clustered_df_old = clustering(olddata, ' num_of_family')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1029,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_of_family</th>\n",
       "      <th>j</th>\n",
       "      <th>X(J)</th>\n",
       "      <th>Y(J)</th>\n",
       "      <th>E(J)</th>\n",
       "      <th>H(J)</th>\n",
       "      <th>E0</th>\n",
       "      <th>A0</th>\n",
       "      <th>log_E0</th>\n",
       "      <th>R</th>\n",
       "      <th>ER</th>\n",
       "      <th>sum_energy</th>\n",
       "      <th>j_new</th>\n",
       "      <th>cluster_pam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-3.013189</td>\n",
       "      <td>-7.227429</td>\n",
       "      <td>4.611031</td>\n",
       "      <td>1255.2500</td>\n",
       "      <td>3366.712</td>\n",
       "      <td>1</td>\n",
       "      <td>3.527206</td>\n",
       "      <td>7.830392</td>\n",
       "      <td>36.106180</td>\n",
       "      <td>370.199507</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>-1.310529</td>\n",
       "      <td>-2.563248</td>\n",
       "      <td>12.047700</td>\n",
       "      <td>1545.0540</td>\n",
       "      <td>3366.712</td>\n",
       "      <td>1</td>\n",
       "      <td>3.527206</td>\n",
       "      <td>2.878841</td>\n",
       "      <td>34.683415</td>\n",
       "      <td>370.199507</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>-2.178048</td>\n",
       "      <td>-2.144561</td>\n",
       "      <td>5.401844</td>\n",
       "      <td>3044.5200</td>\n",
       "      <td>3366.712</td>\n",
       "      <td>1</td>\n",
       "      <td>3.527206</td>\n",
       "      <td>3.056638</td>\n",
       "      <td>16.511481</td>\n",
       "      <td>370.199507</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.965465</td>\n",
       "      <td>-0.082880</td>\n",
       "      <td>5.325506</td>\n",
       "      <td>4715.5230</td>\n",
       "      <td>3366.712</td>\n",
       "      <td>1</td>\n",
       "      <td>3.527206</td>\n",
       "      <td>0.969016</td>\n",
       "      <td>5.160501</td>\n",
       "      <td>370.199507</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>-1.621645</td>\n",
       "      <td>0.079540</td>\n",
       "      <td>15.935060</td>\n",
       "      <td>3044.5200</td>\n",
       "      <td>3366.712</td>\n",
       "      <td>1</td>\n",
       "      <td>3.527206</td>\n",
       "      <td>1.623595</td>\n",
       "      <td>25.872076</td>\n",
       "      <td>370.199507</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27153</th>\n",
       "      <td>1298</td>\n",
       "      <td>6</td>\n",
       "      <td>-1.070832</td>\n",
       "      <td>-0.511355</td>\n",
       "      <td>5.577535</td>\n",
       "      <td>678.2601</td>\n",
       "      <td>25863.250</td>\n",
       "      <td>9</td>\n",
       "      <td>4.412683</td>\n",
       "      <td>1.186661</td>\n",
       "      <td>6.618646</td>\n",
       "      <td>226.805048</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27154</th>\n",
       "      <td>1298</td>\n",
       "      <td>7</td>\n",
       "      <td>-0.093955</td>\n",
       "      <td>-0.075777</td>\n",
       "      <td>64.149700</td>\n",
       "      <td>678.2601</td>\n",
       "      <td>25863.250</td>\n",
       "      <td>9</td>\n",
       "      <td>4.412683</td>\n",
       "      <td>0.120705</td>\n",
       "      <td>7.743186</td>\n",
       "      <td>226.805048</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27155</th>\n",
       "      <td>1298</td>\n",
       "      <td>8</td>\n",
       "      <td>-0.564117</td>\n",
       "      <td>-0.356699</td>\n",
       "      <td>27.180820</td>\n",
       "      <td>678.2601</td>\n",
       "      <td>25863.250</td>\n",
       "      <td>9</td>\n",
       "      <td>4.412683</td>\n",
       "      <td>0.667429</td>\n",
       "      <td>18.141268</td>\n",
       "      <td>226.805048</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27156</th>\n",
       "      <td>1298</td>\n",
       "      <td>9</td>\n",
       "      <td>2.566935</td>\n",
       "      <td>2.136236</td>\n",
       "      <td>8.525503</td>\n",
       "      <td>45614.5600</td>\n",
       "      <td>25863.250</td>\n",
       "      <td>9</td>\n",
       "      <td>4.412683</td>\n",
       "      <td>3.339560</td>\n",
       "      <td>28.471427</td>\n",
       "      <td>226.805048</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27157</th>\n",
       "      <td>1298</td>\n",
       "      <td>10</td>\n",
       "      <td>0.683368</td>\n",
       "      <td>-1.666459</td>\n",
       "      <td>34.196490</td>\n",
       "      <td>45615.9400</td>\n",
       "      <td>25863.250</td>\n",
       "      <td>9</td>\n",
       "      <td>4.412683</td>\n",
       "      <td>1.801132</td>\n",
       "      <td>61.592401</td>\n",
       "      <td>226.805048</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>27158 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        num_of_family   j      X(J)      Y(J)       E(J)        H(J)  \\\n",
       "0                   1   1 -3.013189 -7.227429   4.611031   1255.2500   \n",
       "1                   1   2 -1.310529 -2.563248  12.047700   1545.0540   \n",
       "2                   1   3 -2.178048 -2.144561   5.401844   3044.5200   \n",
       "3                   1   4 -0.965465 -0.082880   5.325506   4715.5230   \n",
       "4                   1   5 -1.621645  0.079540  15.935060   3044.5200   \n",
       "...               ...  ..       ...       ...        ...         ...   \n",
       "27153            1298   6 -1.070832 -0.511355   5.577535    678.2601   \n",
       "27154            1298   7 -0.093955 -0.075777  64.149700    678.2601   \n",
       "27155            1298   8 -0.564117 -0.356699  27.180820    678.2601   \n",
       "27156            1298   9  2.566935  2.136236   8.525503  45614.5600   \n",
       "27157            1298  10  0.683368 -1.666459  34.196490  45615.9400   \n",
       "\n",
       "              E0   A0    log_E0         R         ER  sum_energy  j_new  \\\n",
       "0       3366.712    1  3.527206  7.830392  36.106180  370.199507      0   \n",
       "1       3366.712    1  3.527206  2.878841  34.683415  370.199507      1   \n",
       "2       3366.712    1  3.527206  3.056638  16.511481  370.199507      2   \n",
       "3       3366.712    1  3.527206  0.969016   5.160501  370.199507      3   \n",
       "4       3366.712    1  3.527206  1.623595  25.872076  370.199507      4   \n",
       "...          ...  ...       ...       ...        ...         ...    ...   \n",
       "27153  25863.250    9  4.412683  1.186661   6.618646  226.805048      5   \n",
       "27154  25863.250    9  4.412683  0.120705   7.743186  226.805048      6   \n",
       "27155  25863.250    9  4.412683  0.667429  18.141268  226.805048      7   \n",
       "27156  25863.250    9  4.412683  3.339560  28.471427  226.805048      8   \n",
       "27157  25863.250    9  4.412683  1.801132  61.592401  226.805048      9   \n",
       "\n",
       "       cluster_pam  \n",
       "0                3  \n",
       "1                3  \n",
       "2                3  \n",
       "3                2  \n",
       "4                2  \n",
       "...            ...  \n",
       "27153            0  \n",
       "27154            0  \n",
       "27155            0  \n",
       "27156            3  \n",
       "27157            4  \n",
       "\n",
       "[27158 rows x 14 columns]"
      ]
     },
     "execution_count": 1029,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clustered_df_old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps = 48\n",
    "num_name = ' num_of_family'\n",
    "j_name = ' j'\n",
    "x_name = 'X(J)'\n",
    "y_name = 'Y(J)'\n",
    "e_name = 'E(J)'\n",
    "alg_ind = 'j_new'\n",
    "\n",
    "\n",
    "# создадим словарь кластеров, так как нумерация частиц может быть некорректной\n",
    "points = OneFamily[j_name].unique()\n",
    "clusters = {}\n",
    "for k in points:\n",
    "    clusters[k]=-1\n",
    "k = 0\n",
    "\n",
    "OneFamily[alg_ind] = [i for i in range(len(OneFamily))] # добавляем вспомогательный индекс для выбрасывания частиц\n",
    "dfv = OneFamily[[num_name, j_name, x_name, y_name, e_name, alg_ind]].values\n",
    "dftmp = pd.DataFrame(dfv)\n",
    "check = len(dftmp)\n",
    "\n",
    "minv = np.inf\n",
    "#print(check)\n",
    "\n",
    "while (check!=1) and ((minv < eps) or (minv==np.inf)):\n",
    "    \n",
    "    X = dftmp[2].values\n",
    "    Y = dftmp[3].values\n",
    "    E = dftmp[4].values\n",
    "\n",
    "    distm = Matrix_of_Distance(X, Y, E)\n",
    "    l = distm.shape[0]\n",
    "    distm = distm.values\n",
    "\n",
    "    min_i = 0\n",
    "    min_j = 0\n",
    "    minv = np.inf\n",
    "    for j in range(l):\n",
    "        for i in range(j+1, l):\n",
    "            if distm[j][i]< minv:\n",
    "                min_i = i\n",
    "                min_j = j\n",
    "                minv = distm[j][i]\n",
    "    #print(distm)\n",
    "    print(minv, min_i, min_j)\n",
    "\n",
    "    \n",
    "    if minv < eps:\n",
    "        # если меньше, объединяем точки\n",
    "        # первая точка\n",
    "        ind_i = dfv[min_i][1]\n",
    "        xi = dfv[min_i][2]\n",
    "        yi = dfv[min_i][3]\n",
    "        ei = dfv[min_i][4]\n",
    "\n",
    "        # вторая точка\n",
    "        ind_j = dfv[min_j][1]\n",
    "        xj = dfv[min_j][2]\n",
    "        yj = dfv[min_j][3]\n",
    "        ej = dfv[min_j][4]\n",
    "\n",
    "        if (clusters[ind_j]!=-1) and (clusters[ind_i]==-1):\n",
    "            print('old', ind_j)\n",
    "            #print('max_val=', max(clusters.values()))\n",
    "            clusters[ind_i] = clusters[ind_j]\n",
    "            print(clusters.values())\n",
    "        elif (clusters[ind_i]!=-1) and (clusters[ind_j]==-1):\n",
    "            print('old', ind_i)\n",
    "            #print('max_val=', max(clusters.values()))\n",
    "            clusters[ind_j] = clusters[ind_i]\n",
    "            print(clusters.values())\n",
    "        elif (clusters[ind_j]==-1) or (clusters[ind_i]==-1):\n",
    "            print('new')\n",
    "            clusters[ind_i] = k\n",
    "            clusters[ind_j] = k\n",
    "            k= k + 1\n",
    "            print(clusters.values())\n",
    "        else:\n",
    "            print('two old')\n",
    "\n",
    "            if (clusters[ind_i]!=clusters[ind_j]):\n",
    "\n",
    "                val_to_change= clusters[ind_i]\n",
    "                #print('val_to_change=', clusters[ind_i])\n",
    "\n",
    "                max_val = max(clusters.values())\n",
    "                #print('max_val=', max_val)\n",
    "\n",
    "                #print('ind_i ', clusters[ind_i], 'ind_j ', clusters[ind_j])\n",
    "\n",
    "                # убираем совпавший кластер\n",
    "                clusters = clusters_change(clusters, val_to_change, clusters[ind_j])\n",
    "\n",
    "                # заменяем максимальный номер кластера на тот, что убираем\n",
    "                clusters = clusters_change(clusters, max_val, val_to_change)\n",
    "                k = k - 1\n",
    "\n",
    "            # после обновления значений создаём новый датафрейм\n",
    "            dftmp = df_update(dfv, min_j)\n",
    "            dfv = dftmp.values\n",
    "            # проверка длины\n",
    "            check = len(dfv)\n",
    "            # пересчитываем индексы\n",
    "            \n",
    "            print(clusters.values())\n",
    "            continue\n",
    "\n",
    "        dfv[min_i][1] = ind_i # j\n",
    "        dfv[min_i][2] = (ei*xi+ej*xj)/(ei+ej) # x\n",
    "        dfv[min_i][3] = (ei*yi+ej*yj)/(ei+ej)  # y\n",
    "        dfv[min_i][4] = (ei+ej) # e\n",
    "        dfv[min_i][5] = -1  # j_new\n",
    "        #print(ind_i, ind_j)\n",
    "        #print(min_i, min_j)\n",
    "\n",
    "        # после обновления значений создаём новый датафрейм\n",
    "        dftmp = df_update(dfv, min_j)\n",
    "        dfv = dftmp.values\n",
    "        # проверка длины\n",
    "        check = len(dfv)     \n",
    "    else:\n",
    "        print('minv = ', minv)\n",
    "        #print('k = ', k)\n",
    "        for key in clusters.keys():\n",
    "            if clusters[key]==-1:\n",
    "                clusters[key] = k\n",
    "                k = k + 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
